{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "data = pd.read_csv('/content/Churn_Modelling.csv')\n",
    "\n",
    "# Drop irrelevant columns (RowNumber, CustomerId, and Surname)\n",
    "data = data.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n",
    "\n",
    "# Convert categorical variables to numerical values using one-hot encoding\n",
    "data = pd.get_dummies(data, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "# Define the features (X) and target variable (y)\n",
    "X = data.drop(columns=['Exited'])\n",
    "y = data['Exited']\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Normalize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Build the neural network model\n",
    "def build_model(activation_func):\n",
    "    model = Sequential()\n",
    "    # First hidden layer with 16 neurons and specified activation function\n",
    "    model.add(Dense(16, input_dim=X_train.shape[1], activation=activation_func))\n",
    "    # Second hidden layer with 8 neurons and specified activation function\n",
    "    model.add(Dense(8, activation=activation_func))\n",
    "    # Output layer with 1 neuron (for binary classification) and sigmoid activation\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with Adam optimizer and binary crossentropy loss\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 5: Train and evaluate the model with different activation functions\n",
    "activations = ['relu', 'tanh', 'sigmoid']\n",
    "results = {}\n",
    "\n",
    "for activation in activations:\n",
    "    print(f\"Training model with {activation} activation function...\")\n",
    "    model = build_model(activation)\n",
    "\n",
    "    # Train the model for 10 epochs with a batch size of 32\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Store the accuracy and confusion matrix for each activation function\n",
    "    results[activation] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Confusion Matrix\": cm\n",
    "    }\n",
    "\n",
    "# Step 6: Print the results for each activation function\n",
    "for activation in activations:\n",
    "    print(f\"\\nResults for {activation} activation function:\")\n",
    "    print(f\"Accuracy: {results[activation]['Accuracy']:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results[activation]['Confusion Matrix'])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
